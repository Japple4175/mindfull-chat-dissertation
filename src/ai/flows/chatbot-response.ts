
// This is an autogenerated file from Firebase Studio.
'use server';

/**
 * @fileOverview A chatbot conversation AI agent with persistent memory.
 *
 * - getChatbotResponse - A function that handles the chatbot conversation process.
 * - ChatbotResponseInput - The input type for the getChatbotResponse function.
 * - ChatbotResponseOutput - The return type for the getChatbotResponse function.
 */

import {ai} from '@/ai/genkit';
import {z} from 'genkit';
import { fetchChatHistory, addChatMessage } from '@/services/chat-service';
import type { ConversationMessage } from '@/lib/types';

const ChatbotResponseInputSchema = z.object({
  userId: z.string().describe('The ID of the user engaging in the conversation.'),
  message: z.string().describe('The user message to respond to.'),
});
export type ChatbotResponseInput = z.infer<typeof ChatbotResponseInputSchema>;

const ChatbotResponseOutputSchema = z.object({
  response: z.string().describe('The response from the chatbot.'),
});
export type ChatbotResponseOutput = z.infer<typeof ChatbotResponseOutputSchema>;

// Define a new schema for the prompt that includes conversation history
const PromptInputSchema = z.object({
  message: z.string().describe('The user message to respond to.'),
  conversationHistory: z.array(z.object({
    role: z.enum(['user', 'assistant']),
    content: z.string(),
  })).optional().describe('The conversation history between the user and the bot.')
});


export async function getChatbotResponse(input: ChatbotResponseInput): Promise<ChatbotResponseOutput> {
  return chatbotResponseFlow(input);
}

const prompt = ai.definePrompt({
  name: 'chatbotResponsePromptWithHistory',
  input: {schema: PromptInputSchema}, // Use the new schema here
  output: {schema: ChatbotResponseOutputSchema},
  prompt: `You are a mental health chatbot designed to provide supportive responses to users. Be kind and understanding.
You have access to the previous conversation history with this user. Use it to inform your responses and provide continuity.
Respond to the current user message while taking into account the conversation history.

Conversation history:
{{#each conversationHistory}}
{{role}}: {{content}}
{{/each}}

Current User message: {{{message}}}`,
  config: {
    safetySettings: [
      {
        category: 'HARM_CATEGORY_HATE_SPEECH',
        threshold: 'BLOCK_ONLY_HIGH',
      },
      {
        category: 'HARM_CATEGORY_DANGEROUS_CONTENT',
        threshold: 'BLOCK_NONE',
      },
      {
        category: 'HARM_CATEGORY_HARASSMENT',
        threshold: 'BLOCK_MEDIUM_AND_ABOVE',
      },
      {
        category: 'HARM_CATEGORY_SEXUALLY_EXPLICIT',
        threshold: 'BLOCK_LOW_AND_ABOVE',
      },
    ],
  },
});

const chatbotResponseFlow = ai.defineFlow(
  {
    name: 'chatbotResponseFlow',
    inputSchema: ChatbotResponseInputSchema,
    outputSchema: ChatbotResponseOutputSchema,
  },
  async (input): Promise<ChatbotResponseOutput> => {
    console.log('[Chatbot Flow] Invoked with input:', JSON.stringify(input, null, 2));

    let conversationHistory: ConversationMessage[] = [];
    try {
      conversationHistory = await fetchChatHistory(input.userId);
      console.log(`[Chatbot Flow] Fetched ${conversationHistory.length} past messages for user ${input.userId}`);
    } catch (e: any) {
      console.error(`[Chatbot Flow] Error fetching chat history for user ${input.userId}:`, e.message);
      // Continue without history, or throw error depending on desired behavior
      // For now, we'll let it proceed with an empty history
    }

    try {
      // Save the user's new message to history before calling the AI
      await addChatMessage(input.userId, { role: 'user', content: input.message });
      console.log(`[Chatbot Flow] Saved user message for ${input.userId}`);

      const promptInput = {
        message: input.message,
        conversationHistory: conversationHistory,
      };
      
      const genkitResponse = await prompt(promptInput);

      if (!genkitResponse || !genkitResponse.output) {
        let detailMessage = 'No output from AI model.';
        if (!genkitResponse) {
          detailMessage = 'AI model call did not return a response object.';
        }
        console.error(`[Chatbot Flow] Error: ${detailMessage} Full Genkit response (if available):`, 
          genkitResponse ? JSON.stringify(genkitResponse, null, 2) : 'N/A'
        );
        // Further detailed logging for candidates and safety as before
        if (genkitResponse && genkitResponse.candidates && genkitResponse.candidates.length > 0) {
          genkitResponse.candidates.forEach((candidate, index) => {
            const finishReason = candidate.finishReason;
            const candidateMessageParts = candidate.message?.content; 
            console.error(`[Chatbot Flow] Candidate ${index}: Finish Reason - ${finishReason}`);
            console.error(`[Chatbot Flow] Candidate ${index}: Message Parts - ${JSON.stringify(candidateMessageParts, null, 2)}`);
             if (finishReason === 'SAFETY' && Array.isArray(candidateMessageParts)) {
              let safetyRatingsFound = null;
              for (const part of candidateMessageParts) {
                if (part.custom?.safetyRatings) {
                  safetyRatingsFound = part.custom.safetyRatings;
                  break;
                }
              }
              if (safetyRatingsFound) {
                console.error(`[Chatbot Flow] Candidate ${index} Safety Ratings:`, JSON.stringify(safetyRatingsFound, null, 2));
              } else {
                 console.warn(`[Chatbot Flow] Candidate ${index} finishReason is SAFETY, but safetyRatings not found in expected structure.`);
              }
            }
          });
          throw new Error('The AI model did not return a valid response, potentially due to safety filters. Check server logs.');
        } else if (genkitResponse && (!genkitResponse.candidates || genkitResponse.candidates.length === 0)) {
           console.warn('[Chatbot Flow] Error: AI model response contained no candidates.');
           throw new Error('The AI model response contained no candidates. Check server logs.');
        }
        throw new Error(`[Chatbot Flow] Error: ${detailMessage} Check server logs.`);
      }
      
      if (!genkitResponse.output.response || typeof genkitResponse.output.response !== 'string') {
        console.error('[Chatbot Flow] Error: AI model output is valid, but the response text is missing or not a string. Output:', JSON.stringify(genkitResponse.output, null, 2));
        throw new Error('AI model returned an invalid response format. Expected a text string.');
      }
      
      // Save the AI's response to history
      await addChatMessage(input.userId, { role: 'assistant', content: genkitResponse.output.response });
      console.log(`[Chatbot Flow] Saved assistant response for ${input.userId}`);
      
      return genkitResponse.output;

    } catch (e: any) {
      console.error('[Chatbot Flow] Error caught. Raw error object:', e);
      try {
        console.error('[Chatbot Flow] Error (stringified with sensitive data handling):', 
          JSON.stringify(e, (key, value) => {
            if (typeof value === 'string' && (key.toLowerCase().includes('key') || key.toLowerCase().includes('secret'))) {
              return '[REDACTED]';
            }
            return value;
          }, 2)
        );
      } catch (stringifyError) {
        console.error('[Chatbot Flow] Failed to stringify error object:', stringifyError);
      }
      
      let errorMessage = 'Failed to get chatbot response due to an unexpected error in the AI flow. Check server logs.';
      if (e && e.message) {
        errorMessage = `Failed to get chatbot response: ${e.message}. Check server logs.`;
      } else if (typeof e === 'string') {
        errorMessage = `Failed to get chatbot response: ${e}. Check server logs.`;
      }
      
      throw new Error(errorMessage);
    }
  }
);
