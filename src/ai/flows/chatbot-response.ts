
// This is an autogenerated file from Firebase Studio.
'use server';

/**
 * @fileOverview A chatbot conversation AI agent.
 *
 * - getChatbotResponse - A function that handles the chatbot conversation process.
 * - ChatbotResponseInput - The input type for the getChatbotResponse function.
 * - ChatbotResponseOutput - The return type for the getChatbotResponse function.
 */

import {ai} from '@/ai/genkit';
import {z} from 'genkit';

const ChatbotResponseInputSchema = z.object({
  message: z.string().describe('The user message to respond to.'),
  conversationHistory: z.array(z.object({
    role: z.enum(['user', 'assistant']),
    content: z.string(),
  })).optional().describe('The conversation history between the user and the bot.')
});
export type ChatbotResponseInput = z.infer<typeof ChatbotResponseInputSchema>;

const ChatbotResponseOutputSchema = z.object({
  response: z.string().describe('The response from the chatbot.'),
});
export type ChatbotResponseOutput = z.infer<typeof ChatbotResponseOutputSchema>;

export async function getChatbotResponse(input: ChatbotResponseInput): Promise<ChatbotResponseOutput> {
  return chatbotResponseFlow(input);
}

const prompt = ai.definePrompt({
  name: 'chatbotResponsePrompt',
  input: {schema: ChatbotResponseInputSchema},
  output: {schema: ChatbotResponseOutputSchema},
  prompt: `You are a mental health chatbot designed to provide supportive responses to users. Be kind and understanding. Respond to the user message while taking into account the conversation history.

Conversation history:
{{#each conversationHistory}}
{{role}}: {{content}}
{{/each}}

User message: {{{message}}}`,
  config: {
    safetySettings: [
      {
        category: 'HARM_CATEGORY_HATE_SPEECH',
        threshold: 'BLOCK_ONLY_HIGH',
      },
      {
        category: 'HARM_CATEGORY_DANGEROUS_CONTENT',
        threshold: 'BLOCK_NONE',
      },
      {
        category: 'HARM_CATEGORY_HARASSMENT',
        threshold: 'BLOCK_MEDIUM_AND_ABOVE',
      },
      {
        category: 'HARM_CATEGORY_SEXUALLY_EXPLICIT',
        threshold: 'BLOCK_LOW_AND_ABOVE',
      },
    ],
  },
});

const chatbotResponseFlow = ai.defineFlow(
  {
    name: 'chatbotResponseFlow',
    inputSchema: ChatbotResponseInputSchema,
    outputSchema: ChatbotResponseOutputSchema,
  },
  async (input): Promise<ChatbotResponseOutput> => {
    try {
      const genkitResponse = await prompt(input);

      if (!genkitResponse || !genkitResponse.output) {
        let detailMessage = 'No output from AI model.';
        if (!genkitResponse) {
          detailMessage = 'AI model call did not return a response object.';
        }
        
        console.error(`Chatbot Flow Error: ${detailMessage} Full Genkit response (if available):`, 
          genkitResponse ? JSON.stringify(genkitResponse, null, 2) : 'N/A'
        );

        if (genkitResponse && genkitResponse.candidates && genkitResponse.candidates.length > 0) {
          genkitResponse.candidates.forEach((candidate, index) => {
            const finishReason = candidate.finishReason;
            const candidateMessageParts = candidate.message?.content; // This is an array of parts
            console.error(`Candidate ${index}: Finish Reason - ${finishReason}`);
            console.error(`Candidate ${index}: Message Parts - ${JSON.stringify(candidateMessageParts, null, 2)}`);
            
            if (finishReason === 'SAFETY' && Array.isArray(candidateMessageParts)) {
              let safetyRatingsFound = null;
              for (const part of candidateMessageParts) {
                if (part.custom?.safetyRatings) {
                  safetyRatingsFound = part.custom.safetyRatings;
                  break;
                }
              }
              if (safetyRatingsFound) {
                console.error(`Candidate ${index} Safety Ratings:`, JSON.stringify(safetyRatingsFound, null, 2));
              } else {
                 console.warn(`Candidate ${index} finishReason is SAFETY, but safetyRatings not found in expected structure within message parts.`);
              }
            }
          });
          throw new Error('The AI model did not return a valid response, potentially due to safety filters or other model issues. Please check server logs for candidate details.');
        } else if (genkitResponse && (!genkitResponse.candidates || genkitResponse.candidates.length === 0)) {
          console.warn('Chatbot Flow Error: AI model returned a response, but it contained no candidates.');
          throw new Error('The AI model response contained no candidates. Please check server logs.');
        }
        
        throw new Error(`Chatbot Flow Error: ${detailMessage} Please check server logs.`);
      }
      
      return genkitResponse.output;

    } catch (e: any) {
      console.error('Error caught in chatbotResponseFlow. Raw error object:', e);
      try {
        console.error('Error in chatbotResponseFlow (stringified with sensitive data handling):', 
          JSON.stringify(e, (key, value) => {
            if (typeof value === 'string' && (key.toLowerCase().includes('key') || key.toLowerCase().includes('secret'))) {
              return '[REDACTED]';
            }
            return value;
          }, 2)
        );
      } catch (stringifyError) {
        console.error('Failed to stringify error object in chatbotResponseFlow:', stringifyError);
      }
      
      let errorMessage = 'Failed to get chatbot response. An unexpected error occurred in the AI flow. Please check server logs for more details.';
      if (e && e.message) {
        errorMessage = `Failed to get chatbot response: ${e.message}. Check server logs.`;
      } else if (typeof e === 'string') {
        errorMessage = `Failed to get chatbot response: ${e}. Check server logs.`;
      }
      
      throw new Error(errorMessage);
    }
  }
);
